{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b9495cd7902a6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Holistic AI x UCL AI Society Hackathon Tutorial\n",
    "\n",
    "### Track 2: Building Trustworthy Models for Stereotype Classification in Text Data\n",
    "\n",
    "### Tutorials: Building an Ethical Classifier for Stereotype Detection Using EMGSD\n",
    "\n",
    "This tutorial demonstrated how to build an ethical classifier for stereotype detection using the **Expanded Multi-Grain Stereotype Dataset (EMGSD)**. By incorporating sustainability, fairness, and explainability into the development process, we tackled some of the key challenges in creating trustworthy AI systems.\n",
    "\n",
    "This methodology is inspired by the HEARTS framework from Holistic AI, which is explained in the paper below:\n",
    "\n",
    "[**HEARTS: A Holistic Framework for Explainable, Sustainable, and Robust Text Stereotype Detection**](https://arxiv.org/abs/2409.11579)\n",
    "\n",
    "\n",
    "[**Example stereotype classifier From HEARTS Paper**](https://huggingface.co/holistic-ai/bias_classifier_albertv2)\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Takeaways:\n",
    "1. **Sustainability**: \n",
    "   - Leveraged a small, carbon-efficient model like **ALBERT-V2** to minimize environmental impact without sacrificing performance.\n",
    "   - Used **CodeCarbon** to monitor and reduce carbon emissions during training.\n",
    "\n",
    "2. **Bias Detection**: \n",
    "   - Assessed the fairness of the model across different demographic groups by analyzing counterfactual examples and ensuring consistency in predictions.\n",
    "\n",
    "3. **Explainability**:\n",
    "   - Utilized **SHAP** and **LIME** for token-level transparency, enabling deeper insights into the classifier's decision-making process and promoting trust and accountability.\n",
    "\n",
    "4. **Efficiency and Robustness**:\n",
    "   - Evaluated model performance using **Macro F1 Scores** to ensure generalization across all classes (stereotype, neutral, unrelated).\n",
    "   - Addressed the robustness of the classifier through rigorous testing on diverse texts and demographic combinations.\n",
    "\n",
    "5. **Data Preparation**:\n",
    "   - Simplified data loading, sampling, and preparation to enable flexible experimentation, with clear instructions to scale up for better performance as needed.\n",
    "\n",
    "6. **Modeling and Baselines**:\n",
    "   - Progressed from simple baselines (random selection and logistic regression with TF-IDF) to advanced fine-tuned transformers (ALBERT-V2) to achieve better performance.\n",
    "\n",
    "#### Ethical Considerations:\n",
    "Throughout the tutorial, we ensured adherence to ethical principles such as **bias minimization**, **sustainability**, **efficacy**, **robustness**, and **explainability**. These principles guide the development of trustworthy AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "### Potential Extended Directions:\n",
    "\n",
    "1. **Dataset Enhancement Through Additional Tutorials**:  \n",
    "   - Enrich the dataset and improve model performance by exploring the following tutorials:\n",
    "     - **[Scraping Biased Data](https://github.com/holistic-ai/hai-ucl-hackathon/blob/main/track2_text_stereotype_classification/Extra_Scraping_Biased_Data.ipynb)**: Collect and preprocess real-world biased text data from online sources to make the dataset more diverse and comprehensive.\n",
    "     - **[Generating Biased Data](https://github.com/holistic-ai/hai-ucl-hackathon/blob/main/track2_text_stereotype_classification/Extra_Generate_Biased_Data.ipynb)**: Fine-tune a biased GPT-2 model to generate stereotype-related text. Use this synthetic data to augment the EMGSD dataset for further experimentation.\n",
    "\n",
    "2. **Debiasing Techniques**:  \n",
    "   - Implement strategies such as counterfactual fairness to further enhance the fairness of the classifier and minimize demographic biases.\n",
    "\n",
    "3. **Further Explainability**:  \n",
    "   - Integrate advanced interpretability methods (e.g., Integrated Gradients, BERTViz) to provide more detailed insights into the classifier's predictions.\n",
    "\n",
    "4. **Real-World Testing**:  \n",
    "   - Extend the modelâ€™s application to real-world scenarios by incorporating multi-modal data or testing in diverse, dynamic environments.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "By following this tutorial, you have built a solid foundation for developing trustworthy AI systems. The outlined **future directions** and optional tutorials provide opportunities to expand your efforts, explore novel solutions, and contribute meaningfully to the field of ethical AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226f96d6b5a953b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Setup and Dependencies\n",
    "\n",
    "Install the necessary libraries to get started:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84653b658ed4313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:24:04.846476Z",
     "start_time": "2024-11-23T02:24:02.163155Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch datasets shap pandas scikit-learn accelerate matplotlib codecarbon==2.4.2 lime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521834069b569c21",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We'll focus on an ethical approach, emphasizing sustainability (using a small model like ALBERT-V2), bias detection, explainability (SHAP and LIME), and efficiency.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c980631218b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Loading (EMGSD)\n",
    "\n",
    "The dataset you're using is **EMGSD**: **Expanded Multi-Grain Stereotype Dataset**, which includes stereotype-labeled text across various demographics.\n",
    "\n",
    "# **Expanded Multi-Grain Stereotype Dataset (EMGSD)**\n",
    "\n",
    "## **Dataset Overview**\n",
    "This dataset is designed for detecting and classifying stereotypes across different dimensions, such as **race**, **gender**, **nationality**, and **profession**. It contains both **train** and **test** splits, each with various text samples annotated for bias and stereotype labels.\n",
    "\n",
    "### **Main Features:**\n",
    "\n",
    "- **`text_with_marker`**: The original text with certain words highlighted using \"===\" to indicate the focus of potential stereotypes (e.g., \"The ===doctor=== was helpful\").\n",
    "  \n",
    "- **`text`**: The same text without any markers or highlights. This feature provides a clean version of the text for tasks like natural language processing without needing special token handling.\n",
    "\n",
    "- **`category`**: This column contains the main classification label indicating whether the text contains a **stereotype** or is **unrelated** or **neutral**. The categories include:\n",
    "  - `stereotype`\n",
    "  - `unrelated`\n",
    "  - `neutral`\n",
    "\n",
    "- **`stereotype_type`**: Describes the category of the stereotype detected in the text. Categories include:\n",
    "  - `race`\n",
    "  - `gender`\n",
    "  - `nationality`\n",
    "  - `profession`\n",
    "  - ... and more\n",
    "  \n",
    "- **`data_source`**: The source of the text, indicating where the data sample was originally extracted from. Examples include:\n",
    "  - `stereoset_intrasentence`\n",
    "  - `stereoset_intersentence`\n",
    "  - `seegull_augmented`\n",
    "  - ... and more\n",
    "\n",
    "- **`label`**: A more detailed label indicating the specific type of stereotype detected. Examples include:\n",
    "  - `stereotype_nationality`\n",
    "  - `stereotype_gender`\n",
    "  - `neutral_race`\n",
    "  - ... and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf88e9eb0086c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:24:07.528475Z",
     "start_time": "2024-11-23T02:24:04.847581Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
    "train_data = pd.read_csv(\"hf://datasets/holistic-ai/EMGSD/\" + splits[\"train\"])\n",
    "test_data = pd.read_csv(\"hf://datasets/holistic-ai/EMGSD/\" + splits[\"test\"])\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30342d2edccd7827",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Preparation and Splitting\n",
    "\n",
    "In this section, we load the **Expanded Multi-Grain Stereotype Dataset (EMGSD)** and prepare it for training and testing. The dataset is split into **training** and **testing** subsets, which are essential for building and evaluating our classifier.\n",
    "\n",
    "For demonstration purposes and to speed up the training process during this tutorial, we use **only 10% of the data** by setting `sample_ratio = 0.1`.  \n",
    "**Note:** This is intended for testing purposes only. For better results in your final implementation, **you should adjust this ratio to use a larger portion or the entire dataset**.\n",
    "\n",
    "Hereâ€™s a summary of the process:\n",
    "- **Load the dataset**: Import the training and testing data.\n",
    "- **Sampling**: Use the `sample_ratio` to define the proportion of data used.  \n",
    "  _Example_: Setting `sample_ratio = 0.1` means using only 10% of the dataset.\n",
    "- **Prepare inputs and labels**: Extract the `text` column as input data (`X`) and the `category` column as labels (`y`).\n",
    "\n",
    "By default:\n",
    "- **`train_data`** contains a subset of the original dataset for training.\n",
    "- **`test_data`** is similarly reduced for quick evaluation.\n",
    "\n",
    "### Important:  \n",
    "You can **modify the `sample_ratio`** to include more data as needed for your experiments or to achieve better performance in real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe845a53be36ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:24:07.537249Z",
     "start_time": "2024-11-23T02:24:07.529494Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Use a subset of the data for faster training\n",
    "sample_ratio = 0.01\n",
    "train_data = train_data.sample(frac=sample_ratio, random_state=42)\n",
    "test_data = test_data.sample(frac=sample_ratio, random_state=42)\n",
    "\n",
    "# Prepare train and test sets by using both training and testing data\n",
    "X_train, y_train = train_data[\"text\"].values.tolist(), train_data[\"category\"].values.tolist()\n",
    "X_test, y_test = test_data[\"text\"].values.tolist(), test_data[\"category\"].values.tolist()\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb299f157a0dc85",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Selection and Sustainability Focus\n",
    "\n",
    "We will fine-tune a series of **multi-class** classifiers on the stereotype detection task, tracking carbon emissions with CodeCarbon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee73e829e26",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Macro F1 Score Calculation\n",
    "\n",
    "We will use the **Macro F1 score** to evaluate the model's performance, ensuring that it generalizes well across all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec96452aea95e80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:24:07.661757Z",
     "start_time": "2024-11-23T02:24:07.538126Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute Macro F1 score\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    f1 = f1_score(labels, predictions, average='macro')  # Use macro F1\n",
    "    return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31754ed6c26f7eb5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Training the Models and Tracking Emissions\n",
    "\n",
    "We start with simple baseline models. The first will select the target variable at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4746bf-6da7-4d0d-8311-c549b23f4190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:24:07.937735Z",
     "start_time": "2024-11-23T02:24:07.664128Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import Dataset\n",
    "\n",
    "# Convert to Hugging Face dataset format\n",
    "train_dataset = Dataset.from_dict({\"text\": X_train, \"label\": y_train})\n",
    "test_dataset = Dataset.from_dict({\"text\": X_test, \"label\": y_test})\n",
    "\n",
    "# Map labels to IDs\n",
    "label2id = {\n",
    "    'stereotype': 0,\n",
    "    'unrelated': 1,\n",
    "    'neutral': 2,\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "def map_labels(example):\n",
    "    example['label'] = label2id[example['label']]\n",
    "    return example\n",
    "\n",
    "# Apply the mapping to your dataset\n",
    "train_dataset = train_dataset.map(map_labels)\n",
    "test_dataset = test_dataset.map(map_labels)\n",
    "\n",
    "# Random Model Prediction\n",
    "random.seed(42)\n",
    "random_predictions = [random.choice(y_test) for _ in range(len(y_test))]\n",
    "\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, random_predictions, average='macro')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b1aca-5d5c-40d4-af07-3766568187f3",
   "metadata": {},
   "source": [
    "Next we explore a logistic regression model, with feature vectorization using TF-IDF scores. This model should perform as a stronger baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08de58-a97f-4d33-80c3-8251ce39f091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:24:11.666550Z",
     "start_time": "2024-11-23T02:24:07.938588Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "X_train = train_dataset['text']\n",
    "y_train = train_dataset['label']  \n",
    "X_test = test_dataset['text']\n",
    "y_test = test_dataset['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Tracking emissions with CodeCarbon\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "emissions = tracker.stop()\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Training carbon emissions: {emissions} kg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94f229-33d2-4e02-a9fc-1035031da207",
   "metadata": {},
   "source": [
    "Now, we seek to improve performance against the simple baselines. \n",
    "\n",
    "We will select with the **ALBERT-V2** architecture, a carbon-efficient model with a smaller parameter size than common alternatives such as the LLaMA or GPT series, ensuring sustainability in our approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1922b356a05352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:27:27.456737Z",
     "start_time": "2024-11-23T02:24:11.667730Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], padding='max_length', truncation=True)\n",
    "    \n",
    "# Apply the tokenizer to the dataset\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load pre-trained ALBERT model with classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"albert-base-v2\", \n",
    "    num_labels=3, \n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # \"mps\" For macOS (Apple Silicon)\n",
    "model.to(device)\n",
    "\n",
    "# Tracking emissions with CodeCarbon\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "# Fine-tuning the model and save the best model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir='./logs',\n",
    "    num_train_epochs=3,\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics,  # Use macro F1 computation\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "emissions = tracker.stop()\n",
    "print()\n",
    "print(f\"Training carbon emissions: {emissions} kg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5eaa6b-525f-455d-bf1a-c97fcbf6fc62",
   "metadata": {},
   "source": [
    "We'll benchmark the efficacy of the model using macro F1-scores and check its robustness by testing it against a range of diverse texts and demographic combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d128d7-86d9-474e-a65f-e8c276372141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:27:32.957722Z",
     "start_time": "2024-11-23T02:27:27.458308Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Making predictions on the test set\n",
    "preds = trainer.predict(tokenized_test_dataset).predictions.argmax(-1)\n",
    "f1 = f1_score(tokenized_test_dataset['label'], preds, average='macro')\n",
    "print(f\"Macro F1 Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3415fb09-3f72-427b-92d3-fea53a1b9ff3",
   "metadata": {},
   "source": [
    "You can see from the relatively low macro F1 score that stereotype classification is a very challenging task! How could we improve performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152902cb53292903",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluating Ethical Aspects: Bias\n",
    "\n",
    "#### Bias Assessment\n",
    "We will ensure the classifier treats different demographic groups fairly. We'll analyze the modelâ€™s bias by creating counterfactuals and examining prediction consistency. For a systematic approach, please refer to the paper below:\n",
    "\n",
    "[**Assessing Bias in Metric Models for LLM Open-Ended Generation Bias Benchmarks**](https://arxiv.org/abs/2410.11059)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b4cc05f906db1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:27:33.200127Z",
     "start_time": "2024-11-23T02:27:32.958847Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the text classification pipeline\n",
    "classifier = pipeline(\"text-classification\", model=trainer.model, tokenizer=trainer.tokenizer,top_k=3)\n",
    "\n",
    "def assess_bias(model, counterfactuals):\n",
    "    bias_results = {}\n",
    "    for text in counterfactuals:\n",
    "        prediction = model(text)\n",
    "        bias_results[text] = prediction\n",
    "    return bias_results\n",
    "\n",
    "\n",
    "# Creating demographic counterfactuals (example)\n",
    "counterfactuals = [\"Males usually think that the chef is talented.\", \"Females often assume that the nurse is dedicated.\"]\n",
    "bias_results = assess_bias(classifier, counterfactuals)\n",
    "\n",
    "bias_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02e185c7be1ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Explainability Using SHAP and LIME\n",
    "\n",
    "Explainability is key to ethical AI. Weâ€™ll use **SHAP** and **LIME** to offer transparency into how the model makes decisions at the token level.\n",
    "\n",
    "##### SHAP Example:\n",
    "\n",
    "We'll use SHAP to explain the model's predictions at the token level. Here, we'll explain the first counterfactual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59a3eb1cb8b210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:27:42.612109Z",
     "start_time": "2024-11-23T02:27:33.201151Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(classifier)\n",
    "shap_values = explainer(counterfactuals)\n",
    "\n",
    "shap_values_stereotype = shap_values[:, :, \"stereotype\"].values\n",
    "shap_vectors = []\n",
    "\n",
    "# Save SHAP values in vectors for subsequent calculation\n",
    "for index, values in enumerate(shap_values_stereotype):\n",
    "    # Trim to exclude whitespace and punctuation \n",
    "    trimmed_values = values[1:-2]\n",
    "    shap_vectors.append(trimmed_values)\n",
    "    print(f\"Sentence {index+1} SHAP vector: {trimmed_values}\")\n",
    "\n",
    "shap.plots.text(shap_values[:, :, \"stereotype\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a6cead4c0385",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### LIME Example:\n",
    "\n",
    "Likewise, we can use LIME to explain the model's predictions at the token level. Here, we'll explain the first counterfactual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0cf83567c9338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:27:47.596045Z",
     "start_time": "2024-11-23T02:27:42.613134Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "def predict_proba(texts):\n",
    "    preds = classifier(texts)\n",
    "    probabilities = np.array([[pred['score'] for pred in preds_single] for preds_single in preds])\n",
    "    return probabilities\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=[\"stereotype\", \"neutral\", \"unrelated\"])\n",
    "\n",
    "lime_values_per_sentence = []\n",
    "\n",
    "for idx, sentence in enumerate(counterfactuals):\n",
    "    exp = explainer.explain_instance(sentence, predict_proba, num_features=50, num_samples=100, top_labels=1)\n",
    "    feature_importances = exp.as_list(label=0)\n",
    "    \n",
    "    lime_values = [weight for _, weight in feature_importances]\n",
    "    lime_values_per_sentence.append(lime_values)\n",
    "    \n",
    "    print(f\"LIME values for Sentence {idx+1} 'stereotype':\", lime_values)\n",
    "\n",
    "    exp.show_in_notebook() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01baadd9-4282-449c-97f9-2d4a36ca0daa",
   "metadata": {},
   "source": [
    "Do the explanations provided by these methods align? Let's check an example by computing cosine similarity between the SHAP and LIME values for the first text instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0790c-0ebd-4a1c-9e74-cb15af662206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T02:27:47.849994Z",
     "start_time": "2024-11-23T02:27:47.597234Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot and compare SHAP and LIME explanations\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(shap_vectors[0], label=\"SHAP\")\n",
    "plt.plot(lime_values_per_sentence[0], label=\"LIME\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Token position\")\n",
    "plt.ylabel(\"Explanation value\")\n",
    "plt.title(\"SHAP and LIME Explanations Comparison\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculating cosine similarity between SHAP and LIME vectors\n",
    "for idx, (shap_vec, lime_vec) in enumerate(zip(shap_vectors, lime_values_per_sentence)):\n",
    "    shap_vec_array = np.array(shap_vec)\n",
    "    lime_vec_array = np.array(lime_vec)\n",
    "\n",
    "    similarity = cosine_similarity([shap_vec_array], [lime_vec_array])[0][0]\n",
    "    print(f\"Cosine similarity between SHAP and LIME for Sentence {idx + 1} ({counterfactuals[idx]}): {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4bf1939266f665",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Conclusion: Building an Ethical Classifier\n",
    "\n",
    "This tutorial demonstrated how to build an ethical classifier for stereotype detection using the **Expanded Multi-Grain Stereotype Dataset (EMGSD)**. By incorporating sustainability, fairness, and explainability into the development process, we tackled some of the key challenges in creating trustworthy AI systems.\n",
    "\n",
    "#### Key Takeaways:\n",
    "1. **Sustainability**: \n",
    "   - Leveraged a small, carbon-efficient model like **ALBERT-V2** to minimize environmental impact without sacrificing performance.\n",
    "   - Used **CodeCarbon** to monitor and reduce carbon emissions during training.\n",
    "\n",
    "2. **Bias Detection**: \n",
    "   - Assessed the fairness of the model across different demographic groups by analyzing counterfactual examples and ensuring consistency in predictions.\n",
    "\n",
    "3. **Explainability**:\n",
    "   - Utilized **SHAP** and **LIME** for token-level transparency, enabling deeper insights into the classifier's decision-making process and promoting trust and accountability.\n",
    "\n",
    "4. **Efficiency and Robustness**:\n",
    "   - Evaluated model performance using **Macro F1 Scores** to ensure generalization across all classes (stereotype, neutral, unrelated).\n",
    "   - Addressed the robustness of the classifier through rigorous testing on diverse texts and demographic combinations.\n",
    "\n",
    "5. **Data Preparation**:\n",
    "   - Simplified data loading, sampling, and preparation to enable flexible experimentation, with clear instructions to scale up for better performance as needed.\n",
    "\n",
    "6. **Modeling and Baselines**:\n",
    "   - Progressed from simple baselines (random selection and logistic regression with TF-IDF) to advanced fine-tuned transformers (ALBERT-V2) to achieve better performance.\n",
    "\n",
    "#### Ethical Considerations:\n",
    "Throughout the tutorial, we ensured adherence to ethical principles such as **bias minimization**, **sustainability**, **efficacy**, **robustness**, and **explainability**. These principles guide the development of trustworthy AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "### Potential Extended Directions:\n",
    "\n",
    "1. **Dataset Enhancement Through Additional Tutorials**:  \n",
    "   - Enrich the dataset and improve model performance by exploring the following tutorials:\n",
    "     - **[Scraping Biased Data](https://github.com/holistic-ai/hai-ucl-hackathon/blob/main/track2_text_stereotype_classification/Extra_Scraping_Biased_Data.ipynb)**: Collect and preprocess real-world biased text data from online sources to make the dataset more diverse and comprehensive.\n",
    "     - **[Generating Biased Data](https://github.com/holistic-ai/hai-ucl-hackathon/blob/main/track2_text_stereotype_classification/Extra_Generate_Biased_Data.ipynb)**: Fine-tune a biased GPT-2 model to generate stereotype-related text. Use this synthetic data to augment the EMGSD dataset for further experimentation.\n",
    "\n",
    "2. **Debiasing Techniques**:  \n",
    "   - Implement strategies such as counterfactual fairness to further enhance the fairness of the classifier and minimize demographic biases.\n",
    "\n",
    "3. **Further Explainability**:  \n",
    "   - Integrate advanced interpretability methods (e.g., Integrated Gradients, BERTViz) to provide more detailed insights into the classifier's predictions.\n",
    "\n",
    "4. **Real-World Testing**:  \n",
    "   - Extend the modelâ€™s application to real-world scenarios by incorporating multi-modal data or testing in diverse, dynamic environments.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "By following this tutorial, you have built a solid foundation for developing trustworthy AI systems. The outlined **future directions** and optional tutorials provide opportunities to expand your efforts, explore novel solutions, and contribute meaningfully to the field of ethical AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
